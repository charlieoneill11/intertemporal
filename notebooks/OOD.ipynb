{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946ed748-c6f6-492a-a6a3-8e70c163d1ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.07/lib/python3.9/site-packages/xgboost/__init__.py:9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DMatrix, DeviceQuantileDMatrix, Booster, DataIter\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, cv\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rabit  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.07/lib/python3.9/site-packages/xgboost/core.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (STRING_TYPES, DataFrame, py_str, PANDAS_INSTALLED,\n\u001b[1;32m     24\u001b[0m                      lazy_isinstance)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_lib_path\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# c_bst_ulong corresponds to bst_ulong defined in xgboost/c_api.h\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1040\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc0ca3-63f2-4d63-90cf-36fe10e16f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name=\"charles_oneill\"):\n",
    "    # load training data\n",
    "    train = pd.read_csv(f\"~/intertemporal/data/{name}_train.csv\")\n",
    "    #train = pd.read_csv(\"~/intertemporal/data/charles_oneill_kirby.csv\")\n",
    "    cols = [\"SIR\", \"LDR\", \"Delay\", \"Answer\"]\n",
    "    # load testing data\n",
    "    test = pd.read_csv(f\"~/intertemporal/data/{name}_test.csv\")\n",
    "    #test = pd.read_csv(\"~/intertemporal/data/charles_oneill_kirby.csv\")\n",
    "    return train[cols], test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79cb2a-369b-4775-99ed-2b117298388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data(name=\"jack_miller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3851f4-c37e-4b0a-a59c-88f33d407b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop(columns=['Answer']), train.Answer.values\n",
    "X_test, y_test = test.drop(columns=['Answer']), test.Answer.values\n",
    "trans_train = Normalizer().fit(X_train)\n",
    "trans_test = Normalizer().fit(X_test)\n",
    "X_train = trans_train.transform(X_train)\n",
    "X_test = trans_test.transform(X_test)\n",
    "\n",
    "xbc = xgb.XGBClassifier(verbosity=0, random_seed=1)\n",
    "#xbc = LogisticRegression()\n",
    "xbc.fit(X_train, y_train)\n",
    "preds = xbc.predict(X_test)\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "ec7af201-7052-4657-9f51-27c622b6df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_choice(k, sir, ldr, delay, real_choice):\n",
    "    # From Chabris & Laibson (2008)\n",
    "    # We calculate the likelihood of the data (real choice)\n",
    "    # Either takes value 0 or value 1 (immediate or delayed reward, respectively)\n",
    "    # Via the logit functions on the right hand side\n",
    "    if real_choice == 1: \n",
    "        p_choice = np.exp(ldr/(1 + k*delay)) / (np.exp(sir) + np.exp(ldr/(1 + k*delay)))\n",
    "    else:\n",
    "        p_choice = (1 -  (np.exp(ldr/(1 + k*delay)) / (np.exp(sir) + np.exp(ldr/(1 + k*delay)))))\n",
    "    return p_choice\n",
    "\n",
    "def generate_log_likelihood(current_k, train):\n",
    "    # define vector that will store the probability that the model chooses\n",
    "    choice_probs = np.zeros((len(train),1))\n",
    "    for j in range(len(train)):\n",
    "        # load the choice probability vector for every choice\n",
    "        choice_probs[j] = get_prob_choice(current_k, train.SIR.iloc[j], train.LDR.iloc[j], \n",
    "                            train.Delay.iloc[j], train.Answer.iloc[j])\n",
    "    # take sum of logs and negative to work within minimisation framework\n",
    "    return (-1)*np.sum(np.log(choice_probs))\n",
    "\n",
    "def simulate_choice(row, k):\n",
    "    value = (row[\"LDR\"]/(1+k*row[\"Delay\"])) - row[\"SIR\"]\n",
    "    return 1 if value >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "1ca26148-b729-42fd-9560-cbe524715ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data(name=\"jack_miller\")\n",
    "train.SIR /= 100\n",
    "train.LDR /= 100\n",
    "#train.Delay /= 20\n",
    "test.SIR /= 100\n",
    "test.LDR /= 100\n",
    "#test.Delay /= 20\n",
    "\n",
    "X_train, y_train = train.drop(columns=['Answer']), train.Answer.values\n",
    "X_test, y_test = test.drop(columns=['Answer']), test.Answer.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "c153ed1f-b07a-4ce6-9221-2532cf3bc866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 19.838056807148774\n",
       " hess_inv: array([[4.04322136e-08]])\n",
       "      jac: array([0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 37\n",
       "      nit: 7\n",
       "     njev: 15\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.00040275])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(generate_log_likelihood, k_0, args=(train), method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "2ea6a116-d23c-4392-b06d-cb52c72d42f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_0 = 0.002\n",
    "bnds = (0, None)\n",
    "res = minimize(generate_log_likelihood, k_0, args=(train), method='BFGS')\n",
    "k_fit = res.x[0]\n",
    "preds = X_test.apply(simulate_choice, k=k_fit, axis=1)\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "2c11c097-7dca-43bb-ac35-810f91cbd918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004027532805937858"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ce58f-48ee-4d16-84f1-314196810938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
