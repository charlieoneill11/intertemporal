{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e5d35d-edeb-4767-be97-440cc56f74ba",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312cc916-6f38-45b9-9ff7-be616b4fae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10fc66c8-ef53-46af-8e92-b3f369756804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name=\"charles_oneill\"):\n",
    "    # load training data\n",
    "    train = pd.read_csv(f\"~/intertemporal/data/{name}_train.csv\")\n",
    "    cols = [\"SIR\", \"LDR\", \"Delay\", \"Answer\"]\n",
    "    # load testing data\n",
    "    test = pd.read_csv(f\"~/intertemporal/data/{name}_test.csv\")\n",
    "    return train[cols], test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6503583d-6cbd-4ffb-8699-8ca03442c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterFit:\n",
    "    \n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "    \n",
    "    def get_prob_choice(self, k, sir, ldr, delay, real_choice):\n",
    "        if real_choice == 1: \n",
    "            p_choice = np.exp(ldr/(1 + k*delay)) / (np.exp(sir) + np.exp(ldr/(1 + k*delay)))\n",
    "        else:\n",
    "            p_choice = (1 -  (np.exp(ldr/(1 + k*delay)) / (np.exp(sir) + np.exp(ldr/(1 + k*delay)))))\n",
    "        return p_choice\n",
    "\n",
    "    def generate_log_likelihood(self, current_k, train):\n",
    "        # define vector that will store the probability that the model chooses\n",
    "        choice_probs = np.zeros((len(train),1))\n",
    "        for j in range(len(train)):\n",
    "            # load the choice probability vector for every choice\n",
    "            choice_probs[j] = self.get_prob_choice(current_k, train.SIR.iloc[j], train.LDR.iloc[j], \n",
    "                                train.Delay.iloc[j], train.Answer.iloc[j])\n",
    "        # take sum of logs and negative to work within minimisation framework\n",
    "        return (-1)*np.sum(np.log(choice_probs))\n",
    "\n",
    "    def simulate_choice(self, row, k):\n",
    "        value = (row[\"LDR\"]/(1+k*row[\"Delay\"])) - row[\"SIR\"]\n",
    "        return 1 if value >= 0 else 0\n",
    "    \n",
    "    def fit(self):\n",
    "        k_0 = 0.001\n",
    "        res = minimize(self.generate_log_likelihood, k_0, args=(self.train), method='BFGS')\n",
    "        k_fit = res.x[0]\n",
    "        preds = self.test.apply(self.simulate_choice, k=k_fit, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfe53022-b661-4948-9372-11538bca97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, train, test, model, scale=10):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.X_train, self.y_train = train.drop(columns=['Answer']), train.Answer.values\n",
    "        self.X_test, self.y_test = test.drop(columns=['Answer']), test.Answer.values\n",
    "        self.model = model\n",
    "        self.scale = scale\n",
    "        \n",
    "    def normalise(self):\n",
    "        trans_train = Normalizer().fit(self.X_train)\n",
    "        trans_test = Normalizer().fit(self.X_test)\n",
    "        X_train = trans_train.transform(self.X_train)\n",
    "        X_test = trans_test.transform(self.X_test)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def normalise_params(self):\n",
    "        train, test = self.train.copy(), self.test.copy()\n",
    "        train.SIR /= self.scale\n",
    "        train.LDR /= self.scale\n",
    "        test.SIR /= self.scale\n",
    "        test.LDR /= self.scale\n",
    "        return train, test\n",
    "    \n",
    "    def run(self):\n",
    "        # run Model X\n",
    "        X_train, X_test = self.normalise()\n",
    "        self.model.fit(X_train, self.y_train)\n",
    "        model_preds = self.model.predict(X_test)\n",
    "        model_accuracy = accuracy_score(model_preds, self.y_test)\n",
    "        # run ParameterFit\n",
    "        train, test = self.normalise_params()\n",
    "        param = ParameterFit(train, test)\n",
    "        param_preds = param.fit()\n",
    "        param_accuracy = accuracy_score(param_preds, self.y_test)\n",
    "        return model_accuracy, param_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4894a36c-0f9c-4144-b5b4-9b3879128de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88, 0.84)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = load_data(\"jack_miller\")\n",
    "model = xgb.XGBClassifier(verbosity=0)\n",
    "exp = Experiment(train, test, model, scale=50)\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a85f6-a39f-4632-beec-c46e14916dfa",
   "metadata": {},
   "source": [
    "## Separate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa9db2bd-1844-442f-96b8-a6bbf121183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/laura_ferguson.csv\")\n",
    "laura_ferguson_train = df[0:50]\n",
    "laura_ferguson_test = df[50:75]\n",
    "laura_ferguson_kirby = df[75:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1f664bc-98ef-4eb2-9ddd-97f9a3637016",
   "metadata": {},
   "outputs": [],
   "source": [
    "laura_ferguson_train.to_csv(\"~/intertemporal/data/laura_ferguson_train.csv\", index=False)\n",
    "laura_ferguson_test.to_csv(\"~/intertemporal/data/laura_ferguson_test.csv\", index=False)\n",
    "laura_ferguson_kirby.to_csv(\"~/intertemporal/data/laura_ferguson_kirby.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698e4a9-44d3-41ba-8250-a63ad6dea5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
